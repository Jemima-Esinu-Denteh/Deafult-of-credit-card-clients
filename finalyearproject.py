# -*- coding: utf-8 -*-
"""projectcode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rrIdi-hMsLCm7nahb419JX9JPZ36lpeX

### Libraries
"""

import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import RandomizedSearchCV
from scipy import stats
from sklearn import metrics
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from astropy.table import Table, Column

"""# Data Processing

### Import Data
"""

data = pd.read_csv('B:/Personal Development/Datasets/UCI_Credit_Card.csv')

# Rename the target field
data.rename(columns={"default.payment.next.month": "Default"}, inplace=True)

# Drop irrelevant fields
data.drop('ID', axis = 1, inplace = True)

# Identify duplicates
duplicate_rows = data[data.duplicated(keep = False)]

duplicate_rows.to_csv('C:/Users/Sam/Desktop/Python/Personal lessons/Esinu/duplicate_row.csv', index = False)

# Drop duplicates except the first instance 
data = data.drop_duplicates()

# Checking for missing values
print(data.isnull().sum())


categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE',
                        'PAY_0', 'PAY_2', 'PAY_3', 
                        'PAY_4', 'PAY_5', 'PAY_6']

for col in categorical_features:
    data[col] = data[col].astype('category')
    
for col in categorical_features:
    print(data[col].value_counts())

data.info()

"""### Target Variable"""

target = data.Default


# The frequency of defaults
Default_count = data.Default.sum()
Non_default_count = len(data) - Default_count

# Proportion of defaultors to non_defaultors
Percentage_default= round(Default_count/len(data)*100, 1)
Percentage_non_Default = round(Non_default_count/len(data)*100, 1)

 
# Distribution of target variable
plt.figure(figsize=(7,4))
sns.set_context('paper', font_scale=1.2)
sns.countplot('Default',data=data, palette='Greens')
plt.annotate('Non-default: {}'.format(Non_default_count), xy=(-0.3, 15000), xytext=(-0.3, 3000), size=12)
plt.annotate('Default: {}'.format(Default_count), xy=(0.7, 15000), xytext=(0.7, 3000), size=12)
plt.annotate(str(Percentage_non_Default)+" %", xy=(-0.3, 15000), xytext=(-0.1, 8000), size=12)
plt.annotate(str(Percentage_default)+" %", xy=(0.7, 15000), xytext=(0.9, 8000), size=12)
plt.title('COUNT OF CREDIT CARDS', size=14)

"""### Categorical Variable Investigation"""

data['EDUCATION'].unique()

# Recode the education variable
ord_2 = {0:0, 1:1, 2:2, 3:3, 4:4, 5:4, 6:4}
data['EDUCATION'] = data.EDUCATION.map(ord_2)

data['EDUCATION'].unique()

# Recode the marraige variable
data['MARRIAGE'].unique()

# Merge group 0 with 3
ord_1 = {0:3, 1:1, 2:2, 3:3}
data['MARRIAGE'] = data.MARRIAGE.map(ord_1)

data['MARRIAGE'].unique()

"""### EDA"""

entire_data = data

entire_data.head()

"""### Distribution of Categorical Variables

#### Distribution of Gender, Education, Marriage by Default Status
"""

# Creating a new dataframe with categorical variables
subset = entire_data[['SEX', 'EDUCATION', 'MARRIAGE', 'Default']]

fig, axes = plt.subplots(1, 3, figsize=(20, 15), facecolor='white')
fig.suptitle('FREQUENCY OF CATEGORICAL VARIABLES (BY TARGET)')
ax1 = sns.countplot(x="SEX", hue="Default", data=subset, palette="Greens", ax=axes[0])
ax2 = sns.countplot(x="EDUCATION", hue="Default", data=subset, palette="Greens",ax=axes[1])
ax3 = sns.countplot(x="MARRIAGE", hue="Default", data=subset, palette="Greens",ax=axes[2])

"""### Distribution of Limit Balance"""

x1 = list(entire_data[entire_data['Default'] == 1]['LIMIT_BAL'])
x2 = list(entire_data[entire_data['Default'] == 0]['LIMIT_BAL'])

plt.figure(figsize=(12,4))
sns.set_context('paper', font_scale=1.2)

plt.hist([x1, x2], bins = 40, normed=False, color=['steelblue', 'green'])
plt.xlim([0,600000])
plt.legend(['Yes', 'No'], title = 'Default', loc='upper right', facecolor='white')
plt.xlabel('Limit Balance (NT dollar)')
plt.ylabel('Frequency')
plt.title('LIMIT BALANCE HISTOGRAM BY DEFAULT STATUS', SIZE=15)
plt.box(False)

"""### Dsitribution of Age by Target Variable"""

x1 = list(entire_data[entire_data['Default'] == 1]['AGE'])
x2 = list(entire_data[entire_data['Default'] == 0]['AGE'])

plt.hist([x1, x2], bins = 50, normed=False, color=['blue', 'green'])
plt.xlim([0,85])
plt.legend(['Yes', 'No'], title = 'Default', loc='upper right', facecolor='white')
plt.xlabel('AGE')
plt.ylabel('Frequency')
plt.title('AGE HISTOGRAM BY DEFAULT STATUS', SIZE=15)
plt.box(False)

"""#### Gridplot of Bill Statements"""

g = sns.PairGrid(entire_data,vars =['BILL_AMT1', 
                    'BILL_AMT2', 'BILL_AMT3',
                    'BILL_AMT4', 'BILL_AMT5'],
                 hue="Default")
g.map_diag(plt.hist)
g.map_offdiag(plt.scatter)
#g.add_legend()
plt.legend(['No', 'Yes'], title = 'Default', loc='best', facecolor='white')
plt.suptitle("PAIRPLOT OF BILL STATEMENTS")

"""#### Gridplot of Payment Amounts"""

g = sns.PairGrid(entire_data,vars =['PAY_AMT1', 
                    'PAY_AMT2', 'PAY_AMT3',
                    'PAY_AMT4', 'PAY_AMT5', 
                    'PAY_AMT6'],
                 hue="Default")
g.map_diag(plt.hist)
g.map_offdiag(plt.scatter)
#g.add_legend()
plt.legend(['No', 'Yes'], title = 'Default', loc='best', facecolor='white')
plt.suptitle("PAIRPLOT OF PAYMENT AMOUNTS")

entire_data['Default'] = entire_data['Default'].astype('category')

"""####  Correlation heatmap"""

corr = entire_data.corr() # .corr is used to find corelation
f,ax = plt.subplots(figsize=(8, 7))
sns.heatmap(corr, cbar = True,  square = True, annot = False, fmt= '.1f', 
            xticklabels= True, yticklabels= True
            ,cmap="coolwarm", linewidths= .5, ax=ax)
plt.title('CORRELATION MATRIX - HEATMAP', size=18);

"""####  Testing - 1.0"""

# Indepedent T-Test for Limit Balance
x1 = list(entire_data[entire_data['Default'] == 1]['LIMIT_BAL'])
x2 = list(entire_data[entire_data['Default'] == 0]['LIMIT_BAL'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing - 1.1"""

# Indepedent T-Test for AGE
x1 = list(entire_data[entire_data['Default'] == 1]['AGE'])
x2 = list(entire_data[entire_data['Default'] == 0]['AGE'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 1.2"""

# Indepedent T-Test for Bill Amount in Month 1
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT1'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT1'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 1.3"""

# Indepedent T-Test for Bill Amount in Month 2
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT2'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT2'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 1.4"""

# Indepedent T-Test for Biill Amount in Month 3
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT3'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT3'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 1.5"""

# Indepedent T-Test for Biill Amount in Month 4
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT4'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT4'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing - 1.6"""

# Indepedent T-Test for Bill Amount in Month 5
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT5'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT5'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 1.7"""

# Indepedent T-Test for Bill Amount in Month 6
x1 = list(entire_data[entire_data['Default'] == 1]['BILL_AMT6'])
x2 = list(entire_data[entire_data['Default'] == 0]['BILL_AMT6'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing  - 1.8"""

# Indepedent T-Test for Payment Amount in Month 1
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT1'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT1'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing  - 1.9"""

# Indepedent T-Test for Payment Amount in Month 2
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT2'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT2'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing - 2.0"""

# Indepedent T-Test for Payment Amount in Month 3
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT3'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT3'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 2.1"""

# Indepedent T-Test for Payment Amount in Month 4
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT4'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT4'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 2.2"""

# Indepedent T-Test for Payment Amount in Month 5
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT5'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT5'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""#### Testing - 2.3"""

# Indepedent T-Test for Payment Amount in Month 6
x1 = list(entire_data[entire_data['Default'] == 1]['PAY_AMT6'])
x2 = list(entire_data[entire_data['Default'] == 0]['PAY_AMT6'])

t_statistic, p_value = ttest_ind(x1, x2)

print('Test Statistics: {:.3f}'.format(t_statistic))
print('P_value: {:.3f}'.format(p_value))

"""####  Testing - 2.4"""

gender = pd.crosstab(entire_data.SEX, entire_data.Default)
# Chi-square Test for Sex and Default Status

# Crosstab
print(gender)

gender = np.array(gender)


chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""####  Testing - 2.5"""

gender = pd.crosstab(entire_data.EDUCATION, entire_data.Default)
# Chi-square Test for education and default status 

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""####  Testing - 2.6"""

gender = pd.crosstab(entire_data.MARRIAGE, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing - 2.7"""

gender = pd.crosstab(entire_data.PAY_0, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing - 2.8"""

gender = pd.crosstab(entire_data.PAY_2, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing  - 2.9"""

gender = pd.crosstab(entire_data.PAY_3, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing - 3.0"""

gender = pd.crosstab(entire_data.PAY_4, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing  - 3.1"""

gender = pd.crosstab(entire_data.PAY_5, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""#### Testing 3.2"""

gender = pd.crosstab(entire_data.PAY_6, entire_data.Default)
# Chi-square Test marital status and default status

# Crosstab
print(gender)

gender = np.array(gender)

chi2_stat, p_val, dof, ex = stats.chi2_contingency(gender)

print('=== Chi2 Statistic===')
print(chi2_stat)
print('\n')

print('=== Degree of Freedom===')
print(dof)
print('\n')

print('===P-value===')
print(p_val)
print('\n')

print('=== Contigency Table===')
print(ex)

"""# Modeling"""

entire_data['Default'].value_counts()

"""#### Train - Test Split"""

features = entire_data.drop('Default', axis = 1, inplace = False)
target = entire_data.Default

X_train, X_test, y_train, y_test = train_test_split(features, target, stratify = target,test_size = .3, random_state = 44)

"""#### Standardize Dataset"""

scaler = StandardScaler()
scaler.fit(X_train)

X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""#### Default Logistic Regression on Original Data"""

logreg_orig = LogisticRegression()
logreg_orig.fit(X_train, y_train)
print('Training Score: {:.2f}'.format(logreg_orig.score(X_train, y_train)))
print('Test Score: {:.2f}'.format(logreg_orig.score(X_test, y_test)))

logreg_tuned = LogisticRegression()
logreg_tuned.fit(X_train, y_train)
y_pred = logreg_tuned.predict(X_test)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(logreg_tuned, X_train, y_train, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,logreg_tuned.predict(X_test))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""#### Parameter search"""

param_grid = {'C': np.logspace(-5, 8, 15), 'max_iter': np.array(range(100, 1000, 100)), 'solver':('newton-cg', 'lbfgs', 'liblinear')}

# Instantiate a logistic regression classifier
logreg = LogisticRegression()

# Instantiate the RandomizedSearchCV object
logreg_cv = RandomizedSearchCV(logreg,param_grid , cv=5, random_state = 44)

# Fit it to the data
logreg_cv.fit(X_train, y_train)

# Print the tuned parameters and score
print("Tuned Logistic Regression Parameters: {}".format(logreg_cv.best_params_)) 
print('Best cross-validation score: {:.2f}'.format(logreg_cv.best_score_))

results = pd.DataFrame(logreg_cv.cv_results_)
display(results.head())
results.to_csv('C:/Users/Sam/Desktop/Python/Personal lessons/Esinu/logreg_orig.csv', index = False)

"""#### Logistic Regression on the Best Set of Parameters"""

logreg_tuned = LogisticRegression(solver= 'newton-cg', max_iter =  700, C = 2275.846,   random_state=44)
logreg_tuned.fit(X_train, y_train)
y_pred = logreg_tuned.predict(X_test)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(logreg_tuned, X_train, y_train, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,logreg_tuned.predict(X_test))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""#### Logistic Regression on Scaled Data with Default Parameter"""

logreg_scaled = LogisticRegression()
logreg_scaled.fit(X_train_scaled, y_train)
print('Training Score: {:.2f}'.format(logreg_scaled.score(X_train_scaled, y_train)))
print('Test Score: {:.2f}'.format(logreg_scaled.score(X_test_scaled, y_test)))

logreg_tuned = LogisticRegression()
logreg_tuned.fit(X_train_scaled, y_train)
y_pred = logreg_tuned.predict(X_test_scaled)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(logreg_tuned, X_train_scaled, y_train, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,logreg_tuned.predict(X_test_scaled))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""####  Parameter Search for scaled Data"""

param_grid = {'C': np.logspace(-5, 8, 15), 'max_iter': np.array(range(100, 1000, 100)), 'solver':('newton-cg', 'lbfgs', 'liblinear')}

# Instantiate a logistic regression classifier
logreg = LogisticRegression()

# Instantiate the RandomizedSearchCV object
logreg_cv = RandomizedSearchCV(logreg,param_grid , cv=5, random_state=0)

# Fit it to the data
logreg_cv.fit(X_train_scaled, y_train)

# Print the tuned parameters and score
print("Tuned Logistic Regression Parameters: {}".format(logreg_cv.best_params_)) 
print('Best cross-validation score: {:.2f}'.format(logreg_cv.best_score_))

"""#### Results of the grid search"""

results = pd.DataFrame(logreg_cv.cv_results_)
display(results.head())
results.to_csv('C:/Users/Sam/Desktop/Python/Personal lessons/Esinu/logreg_scaled.csv', index = False)

"""#### Logistic Regression model with parameter for scaled data"""

logreg_scaled_param = LogisticRegression(solver = 'liblinear', max_iter = 800, C = 100000000,   random_state=44)
logreg_scaled_param.fit(X_train_scaled, y_train)
print('Training Score: {:.2f}'.format(logreg_scaled_param.score(X_train_scaled, y_train)))
print('Test Score: {:.2f}'.format(logreg_scaled_param.score(X_test_scaled, y_test)))

logreg_tuned = LogisticRegression( solver = 'liblinear', max_iter = 800, C = 100000000,   random_state=44)
logreg_tuned.fit(X_train_scaled, y_train)
y_pred = logreg_tuned.predict(X_test_scaled)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(logreg_tuned, X_train_scaled, y_train, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,logreg_tuned.predict(X_test_scaled))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""#### Random Forest With Default Parameters"""

rf = RandomForestClassifier()
rf.fit(X_train,y_train)
print('Training Accuracy: {:.2f}'.format(rf.score(X_train, y_train)))
print('Test Accuracy: {:.2f}'.format(rf.score(X_test, y_test)))

rf_tuned =RandomForestClassifier()
rf_tuned.fit(X_train, y_train)
y_pred = rf_tuned.predict(X_test)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(rf_tuned, features, target, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,rf_tuned.predict(X_test))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""#### Parameter Search for Random Forest"""

param_dist = {'n_estimators': [50,100,150,200,250],
               "max_features": [1,2,3,4,5,6,7,8,9],
               'max_depth': [1,2,3,4,5,6,7,8,9],
               "criterion": ['gini','entropy']}

rf = RandomForestClassifier()

rf_cv = RandomizedSearchCV(rf, param_distributions = param_dist, 
                           cv = 5, random_state=0, n_jobs = 1)

rf_cv.fit(X_train,y_train)

print("Tuned Random Forest Parameters: {}".format(rf_cv.best_params_))
print('Best cross-validation score: {:.2f}'.format(rf_cv.best_score_))

results = pd.DataFrame(rf_cv.cv_results_)
display(results.head())
results.to_csv('C:/Users/Sam/Desktop/Python/Personal lessons/Esinu/rf_orig.csv', index = False)

"""#### Random Forest on the best parameters"""

rf_param = RandomForestClassifier(n_estimators=200, max_features=6, max_depth=5, criterion='entropy', random_state = 44)

rf_param.fit(X_train, y_train)

print('Training Accuracy: {:.2f}'.format(rf.score(X_train, y_train)))
print('Test Accuracy: {:.2f}'.format(rf.score(X_test, y_test)))

"""#### Cross validation of results for Random Forest"""

rf_tuned =RandomForestClassifier(n_estimators=200, max_features=6, max_depth=5, criterion='entropy')
rf_tuned.fit(X_train, y_train)
y_pred = rf_tuned.predict(X_test)
print('Test Accuracy: {:.3f}'.format(metrics.accuracy_score(y_pred, y_test)))

#Cross Validation
## 10-fold cross-validation 
cv_scores =cross_val_score(rf_tuned, X_train, y_train, cv=5)

# Print the 5-fold cross-validation scores
print()
print(classification_report(y_test, y_pred, target_names = ['No_Default', 'Default']))
print()
print("Average 5-Fold CV Score: {}".format(round(np.mean(cv_scores),4)),
      ", Standard deviation: {}".format(round(np.std(cv_scores),4)))

plt.figure(figsize=(4,3))
ConfMatrix = confusion_matrix(y_test,rf_tuned.predict(X_test))
sns.heatmap(ConfMatrix,annot=True, cmap="Blues", fmt="d", 
            xticklabels = ['Non-default', 'Default'], 
            yticklabels = ['Non-default', 'Default'])
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.title("Confusion Matrix - Logistic Regression");

"""#### Precision, Recall and F-Score for all models"""

data_rows = [('Logistic Regression', 'original_default_parameters', 0.73, 0.78 ,0.68),
             ('Logistic Regression', 'original_tuning_parameters', 0.79, 0.81 , 0.77 ),
             ('Logistic Regression', 'standardized_default_parameters', 0.79, 0.81, 0.77), 
             ('Logistic Regression', 'standardized_tuning_parameters', 0.79, 0.81, 0.77),
              ('Random Forest', 'original_default_parameters', 0.79, 0.81, 0.79),  
             ('Random Forest', 'original_tuning_parameters', 0.80, 0.82, 0.80)
            ]
t = Table(rows=data_rows, names=('Model', 'Data', 'Precision', 'Recall', 'F1'))
print(t)

"""#### Precision, Recall and F-Score for all model prediction of Default Accounts"""

data_rows = [('Logistic Regression', 'original_default_parameters', 0.55, 0.00, 0.01),
             ('Logistic Regression', 'original_tuning_parameters', 0.70, 0.23, 0.35),
             ('Logistic Regression', 'standardized_default_parameters', 0.70, 0.23, 0.35), 
             ('Logistic Regression', 'standardized_tuning_parameters',  0.70, 0.23, 0.35),
              ('Random Forest', 'original_default_parameters', 0.64, 0.36, 0.46),  
             ('Random Forest', 'original_tuning_parameters', 0.67, 0.35, 0.46)
            ]
t1 = Table(rows=data_rows, names=('Model', 'Data', 'Precision', 'Recall', 'F1'))
print(t1)

"""#### ROC Curve and AUC scored"""

y_pred_proba_logreg_orig = logreg_orig.predict_proba(X_test)[::,1]
fpr1, tpr1, _ = metrics.roc_curve(y_test,  y_pred_proba_logreg_orig)
auc1 = metrics.roc_auc_score(y_test, y_pred_proba_logreg_orig)

y_pred_proba_logreg_tuned = logreg_tuned.predict_proba(X_test)[::,1]
fpr2, tpr2, _ = metrics.roc_curve(y_test, y_pred_proba_logreg_tuned)
auc2 = metrics.roc_auc_score(y_test, y_pred_proba_logreg_tuned)

y_pred_proba_scaled_deafault = logreg_scaled.predict_proba(X_test_scaled)[::,1]
fpr3, tpr3, _ = metrics.roc_curve(y_test, y_pred_proba_scaled_deafault)
auc3 = metrics.roc_auc_score(y_test, y_pred_proba_scaled_deafault)

y_pred_proba_scaled_param = logreg_scaled_param.predict_proba(X_test_scaled)[::,1]
fpr4, tpr4, _ = metrics.roc_curve(y_test, y_pred_proba_scaled_param)
auc4 = metrics.roc_auc_score(y_test, y_pred_proba_scaled_param)

y_pred_proba_RF = rf.predict_proba(X_test)[::,1]
fpr5, tpr5, _ = metrics.roc_curve(y_test, y_pred_proba_RF)
auc5 = metrics.roc_auc_score(y_test, y_pred_proba_RF)

y_pred_proba_rf_param = rf_param.predict_proba(X_test)[::,1]
fpr6, tpr6, _ = metrics.roc_curve(y_test, y_pred_proba_rf_param)
auc6 = metrics.roc_auc_score(y_test, y_pred_proba_rf_param)


plt.figure(figsize=(10,7))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr1,tpr1,label="Logistic Regression(Default Parameters), auc="+str(round(auc1,2)))
plt.plot(fpr2,tpr2,label="Logistic Regression(Optimal Parameters), auc="+str(round(auc2,2)))
plt.plot(fpr3,tpr3,label="Logistic Regression_Scaled(Default Parameters), auc="+str(round(auc3,2)))
plt.plot(fpr4,tpr4,label="Logistic Regression_Scaled(Optimal Parameters), auc="+str(round(auc4,2)))
plt.plot(fpr5,tpr5,label="Random Forest (Default Parameters), auc="+str(round(auc5,2)))
plt.plot(fpr6,tpr6,label="Random Forest (Optimal Parameters), auc="+str(round(auc6,2)))
plt.legend(loc=4, title='Models', facecolor='white')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC', size=15)
plt.box(False)